{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d72ef6",
   "metadata": {},
   "source": [
    "# PyTorch Homework\n",
    "## 作業說明\n",
    "這個作業希望以 PyTorch 的框架透過實作讓同學了解基本的讀取資料集、搭建模型以及訓練的過程。\n",
    "\n",
    "這次作業分成三大部份及若干小部份，有一些**被註解框起來的區域**以及 **?** 的部份需要完成。\n",
    "\n",
    "1. **資料準備 - 30%**\n",
    "    + Transformation\n",
    "    + Custom dataset definition - 10%\n",
    "    + Create datasets - 10%\n",
    "    + Create dataloaders - 10%\n",
    "\n",
    "\n",
    "2. **建立模型 - 35%**\n",
    "    + flatten function - 5%\n",
    "    + 使用 nn.Module 建立模型 - 10%\n",
    "    + 使用 nn.Sequential 建立模型 - 10%\n",
    "    + 自己設計模型 - 10%\n",
    "    \n",
    "\n",
    "3. **訓練模型 - 35%**\n",
    "    + Loss function & optimizer - 5%\n",
    "    + 訓練 - 20%\n",
    "        + 完成程式碼 - 10%\n",
    "        + 自行設計的模型測試集準確率(只看最後 5 個 epoch 中的 best accuracy) - 10%\n",
    "            + 達到 50% baseline - 5%\n",
    "            + Bonus: 準確率超過 baseline 越多拿越高 - 5% \n",
    "    + 儲存模型 - 5%\n",
    "    + 繪製 loss 及 accuracy 圖表 - 5%\n",
    "\n",
    "## 作業繳交\n",
    "1. 繳交期限：\n",
    "\n",
    "\n",
    "2. 繳交方式：\n",
    "    \n",
    "    只需繳交這份完成的 ipynb 檔至 moodle，每個 cell 的執行結果都要顯示出來(訓練過程、loss curves 等等)，會用這些結果評分，不需要上傳訓練好的模型。\n",
    "    \n",
    "    檔案命名格式：學號_姓名_hw2.ipynb (ex: F12345678_王大明_hw2.ipynb)\n",
    "    * **格式不對的話會扣 10 分！！！**\n",
    "    \n",
    "\n",
    "3. 有問題請寄信至助教信箱 ne6094041@gs.ncku.edu.tw 或於 TA hour 至資訊新館65601室找助教詢問。\n",
    "    + TA hour: 星期一和四 14:00 ~ 16:30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e84958",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219b736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchviz import make_dot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef8591",
   "metadata": {},
   "source": [
    "## Hyperparamters\n",
    "可以自行新增或調整需要的 hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3793fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# data\n",
    "DATA_PATH = 'stanford_dog'\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "MEAN, STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225) # mean and std for ImageNet\n",
    "\n",
    "# training\n",
    "LR = 1e-3\n",
    "EPOCHS = 40\n",
    "USE_CUDA = True # use cuda or not\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c1abd",
   "metadata": {},
   "source": [
    "## GPU Setting\n",
    "用 ```torch.cuda.is_available()``` 測試系統是否能使用 cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c987829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 for training.\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if USE_CUDA and torch.cuda.is_available(): # 若想使用 cuda 且可以使用 cuda\n",
    "    device = 'cuda:1'\n",
    "print(f'Using {device} for training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7240b838",
   "metadata": {},
   "source": [
    "## 1. Preparing Dataset\n",
    "PyTorch 中處理資料的部份主要由兩種 API 組成:\n",
    "+ ```Dataset```: 定義如何讀取資料，並對資料做前處理(搭配 ```transforms```)\n",
    "+ ```DataLoader```: 負責將多個樣本打包成 mini-batch 、處理資料取樣、以 multi-threading 或 multi-processing 的方式讀取資料等等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab07be",
   "metadata": {},
   "source": [
    "### 1.1 Transformations\n",
    "Pytorch 的 ```transforms``` API 包含許多常用的方法，如縮放、剪裁、翻轉、旋轉、自定義 transform 等等，也包含不同影像格式之間與 tensor 的型態轉換。\n",
    "\n",
    "每個 transform 方法可以單獨地被套用在影像上，也可以使用 ```Compose()``` 將許多方法組合在一起，並且會自動地照組合順序套用在影像上\n",
    "\n",
    "這裡的 transformations 是常見且基本的組合，雖然這裡不需要填寫，但你可以在裡面增加一些 augmentation 幫助後面的模型訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37b1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=MEAN, std=STD)\n",
    "\n",
    "# a set of common trasnformation combination for training\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# transformations for testing do not need to do fancy tricks\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db351d80",
   "metadata": {},
   "source": [
    "### 1.2 定義 dataset\n",
    "自定義的資料集會繼承 ```Dataset```，並且 overwrite 以下 3 個 function:\n",
    "1. ```__init__```: 建立資料集中樣本的讀取路徑以及 label 清單\n",
    "2. ```__len__```: 回傳資料集大小，即樣本的數量\n",
    "3. ```__getitem__```: 實際讀取資料的 function ，根據給定的 index 讀取影像，並對影像進行 transformation ，最後回傳處理過的影像以及其 label 。\n",
    "\n",
    "在這裡，我們會將每張影像的讀取路徑儲存在 ```samples``` 裡，其對應的 label 儲存在 ```labels```中。\n",
    "\n",
    "請完成以下 ? 處以及被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c0cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogDataset(Dataset):\n",
    "    def __init__(self, samples, classes, cls_to_idx, transform=None):\n",
    "        \"\"\"\n",
    "        samples: 儲存每張影像的路徑以及 label 的清單\n",
    "        classes: 所有類別名稱的清單\n",
    "        cls_to_idx: 類別和對應 index 的 dict\n",
    "        transform: 要對影像執行的 transformation\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.classes = classes\n",
    "        self.cls_to_idx = cls_to_idx\n",
    "        self.targets = [s[1] for s in samples] # list of labels corresponding to samples\n",
    "        self.samples = [s[0] for s in samples] # list of sample paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.samples[idx]\n",
    "        label = self.targets[idx]\n",
    "    \n",
    "        # load the image using PIL.Image.open()\n",
    "        img = Image.open(path)\n",
    "        \n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab09a8",
   "metadata": {},
   "source": [
    "### 1.3 Create datasets\n",
    "首先找出所有資料的路徑並儲存成清單\n",
    "\n",
    "這裡不用填寫，但需要執行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b521b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 classes and 3633 images.\n"
     ]
    }
   ],
   "source": [
    "def find_files(folder):\n",
    "    \"\"\"\n",
    "    Getting the list of files and their labels.\n",
    "    \n",
    "    Returns:\n",
    "    classes: list of class names\n",
    "    cls_to_idx: dict that map class names to their interger labels\n",
    "    instances: dict that uses labels as keys and the corresponding tuples (samples, # of samples) as values\n",
    "    \"\"\"\n",
    "    # find classes under the folder\n",
    "    folder_path = os.path.expanduser(folder)\n",
    "    classes = os.listdir(folder_path) # class list\n",
    "    cls_to_idx = {name: i for i, name in enumerate(classes)} # {class name: index}\n",
    "        \n",
    "    # find files and make list of them\n",
    "    instances = {}\n",
    "    for cls in sorted(cls_to_idx.keys()):\n",
    "        cls_idx = cls_to_idx[cls]\n",
    "        cls_path = osp.join(folder_path, cls) # path to the class folder\n",
    "        files = [ f for f in os.listdir(cls_path) if f[-3:]==\"jpg\"]  # list of images under the class\n",
    "        items = [(osp.join(cls_path, name), cls_idx) for name in files] # combine them to form complete paths\n",
    "        instances[cls_idx] = (items, len(items)) # (list of samples of the class, num of images in this class)\n",
    "        \n",
    "    return classes, cls_to_idx, instances\n",
    "\n",
    "# get the list of samples under the folder\n",
    "classes, cls_to_idx, instances = find_files(DATA_PATH)\n",
    "print(f'There are {len(classes)} classes and {sum([s[1] for s in instances.values()])} images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3534169",
   "metadata": {},
   "source": [
    "#### Split dataset\n",
    "若資料集本身沒有區分訓練集、驗證集或測試集，我們就必須手動分割出這些子集。\n",
    "\n",
    "這次作業採用「訓練集:測試集 = 8:2」的分割策略，對每個類別中的樣本都採用這個比例，這裡使用 ```sklearn``` 的 ```train_test_split``` 。\n",
    "\n",
    "請完成以下 ? 處以及被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c48c48ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "3\n",
      "18\n",
      "13\n",
      "4\n",
      "12\n",
      "6\n",
      "8\n",
      "11\n",
      "14\n",
      "2\n",
      "0\n",
      "16\n",
      "17\n",
      "9\n",
      "5\n",
      "15\n",
      "10\n",
      "1\n",
      "19\n",
      "Size of train dataset: 2898, size of test dataset: 735\n"
     ]
    }
   ],
   "source": [
    "train_samples = []\n",
    "test_samples = []\n",
    "\n",
    "# iterate through all classes, split the samples and store them in the lists\n",
    "for cls_idx, cls_samples in instances.items():\n",
    "    train, test = train_test_split(cls_samples[0], test_size=0.2, random_state=SEED)  # split\n",
    "    train_samples += train\n",
    "    test_samples += test\n",
    "    \n",
    "train_dataset = DogDataset(train_samples,classes,cls_to_idx,transform=train_transforms)\n",
    "test_dataset = DogDataset(test_samples,classes,cls_to_idx,transform=test_transforms)\n",
    "   \n",
    "print('Size of train dataset: %d, size of test dataset: %d' % (len(train_dataset), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c829f",
   "metadata": {},
   "source": [
    "### 1.4 Create dataloaders\n",
    "```DataLoader``` 負責將從 dataset 中得到的東西根據採樣策略 (```sampler```)、batch size 大小 (```batch_size```)、是否打亂資料順序 (```shuffle```)（訓練時通常會打亂），將樣本打包成一個 mini-batch ，並根據 ```num_workers``` 調整讀取資料的所需的資源。\n",
    "\n",
    "從 dataloader 中讀取資料的方式為像 python generator 或 list 一樣使用迴圈取出資料，可以在後面的訓練階段中看到。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "337882b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91 training batches and 23 testing batches\n"
     ]
    }
   ],
   "source": [
    "train_loader = None\n",
    "test_loader = None  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,num_workers=4)   \n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,num_workers=4)   \n",
    "\n",
    "print(f'There are {len(train_loader)} training batches and {len(test_loader)} testing batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe672d",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "PyTorch 的模型（包括基本的 conv, batchnorm 層等等）大部分都是繼承 ```nn.Module```，並且都具備 \n",
    "+ ```__init__```: 定義內部結構，例如 conv, pool 等等。\n",
    "+ ```forward```: 定義前面的結構操作如何串聯，也就是這些結構的順序，是輸入的張量真正進行計算的 function 。\n",
    "\n",
    "用來建立模型的 API 有很多種，包括 ```nn.Module```、```nn.Sequential```、```nn.ModuleList```、```nn.ModuleDict``` 等等。\n",
    "\n",
    "這次作業要求以前兩種方法建立模型，分成 2.1 以及 2.2，並在這兩個部分裡完成下面所敘述的模型結構：\n",
    "1. A convolution layer with 64 11*11 filters, stride 4 and padding 2\n",
    "2. ReLU\n",
    "3. A Maxpooling layer with 3*3 kernel and stride 2\n",
    "4. A convolution layer with 128 5*5 filters and padding 2\n",
    "5. ReLU\n",
    "6. A Maxpooling layer with 3*3 kernel and stride 2\n",
    "7. A convolution layer with 256 3*3 filters and padding 1\n",
    "8. ReLU\n",
    "9. A convolution layer with 128 3*3 filters and padding 1\n",
    "10. ReLU\n",
    "11. A convolution layer with 128 3*3 filters and padding 1\n",
    "12. ReLU\n",
    "13. A Maxpooling layer with 3*3 kernel and stride 2\n",
    "14. flatten\n",
    "15. A fully-connected layer that outputs tensor to 1024\n",
    "16. ReLU\n",
    "17. A fully-connected layer that outputs tensor to 256\n",
    "18. ReLU\n",
    "19. A fully-connected layer that outputs tensor to 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0911c3",
   "metadata": {},
   "source": [
    "### 2.1 flatten function\n",
    "Flatten 作用是將 tensor 除了 batch 以外的其他維度全部攤平。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "316c953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    x = torch.flatten(x ,  start_dim = 1 )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34fbd6a",
   "metadata": {},
   "source": [
    "### 2.2 使用 nn.Module 建立模型\n",
    "如同一般定義 python class 的方法，在建構子中定義會用到的 layer ，並在 forward 中定義其之間的操作連結。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3081d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"934pt\" height=\"1177pt\"\n",
       " viewBox=\"0.00 0.00 933.54 1177.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(.8951 .8951) rotate(0) translate(4 1311)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1311 1039,-1311 1039,4 -4,4\"/>\n",
       "<!-- 140432442521472 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140432442521472</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"838,-31 773,-31 773,0 838,0 838,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"805.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (4, 20)</text>\n",
       "</g>\n",
       "<!-- 140432442502544 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140432442502544</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"853,-86 758,-86 758,-67 853,-67 853,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"805.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140432442502544&#45;&gt;140432442521472 -->\n",
       "<g id=\"edge54\" class=\"edge\">\n",
       "<title>140432442502544&#45;&gt;140432442521472</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M805.5,-66.9688C805.5,-60.1289 805.5,-50.5621 805.5,-41.5298\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"809.0001,-41.3678 805.5,-31.3678 802.0001,-41.3678 809.0001,-41.3678\"/>\n",
       "</g>\n",
       "<!-- 140432442502640 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140432442502640</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"740,-141 639,-141 639,-122 740,-122 740,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"689.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432442502640&#45;&gt;140432442502544 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140432442502640&#45;&gt;140432442502544</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M709.7057,-121.9197C727.9737,-113.2581 755.1018,-100.3957 775.8304,-90.5675\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"777.6004,-93.6018 785.1367,-86.155 774.6014,-87.2768 777.6004,-93.6018\"/>\n",
       "</g>\n",
       "<!-- 140432442521536 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140432442521536</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"734,-207 645,-207 645,-177 734,-177 734,-207\"/>\n",
       "<text text-anchor=\"middle\" x=\"689.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">linear3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"689.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (20)</text>\n",
       "</g>\n",
       "<!-- 140432442521536&#45;&gt;140432442502640 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140432442521536&#45;&gt;140432442502640</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M689.5,-176.7333C689.5,-169.0322 689.5,-159.5977 689.5,-151.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"693.0001,-151.0864 689.5,-141.0864 686.0001,-151.0864 693.0001,-151.0864\"/>\n",
       "</g>\n",
       "<!-- 140432442502592 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140432442502592</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"853,-141 758,-141 758,-122 853,-122 853,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"805.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140432442502592&#45;&gt;140432442502544 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140432442502592&#45;&gt;140432442502544</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M805.5,-121.9197C805.5,-114.9083 805.5,-105.1442 805.5,-96.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"809.0001,-96.3408 805.5,-86.3408 802.0001,-96.3409 809.0001,-96.3408\"/>\n",
       "</g>\n",
       "<!-- 140432442502448 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140432442502448</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"850,-201.5 755,-201.5 755,-182.5 850,-182.5 850,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"802.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140432442502448&#45;&gt;140432442502592 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140432442502448&#45;&gt;140432442502592</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M802.982,-182.2796C803.3907,-174.0376 803.9903,-161.9457 804.5019,-151.629\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"808.0096,-151.5583 805.0092,-141.3972 801.0182,-151.2116 808.0096,-151.5583\"/>\n",
       "</g>\n",
       "<!-- 140432442502784 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140432442502784</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"714,-267.5 613,-267.5 613,-248.5 714,-248.5 714,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432442502784&#45;&gt;140432442502448 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140432442502784&#45;&gt;140432442502448</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M683.7118,-248.403C707.1828,-237.2585 746.1054,-218.7773 772.9649,-206.0238\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"774.7317,-209.0595 782.2638,-201.6085 771.7291,-202.7362 774.7317,-209.0595\"/>\n",
       "</g>\n",
       "<!-- 140432442521344 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140432442521344</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"708,-339 619,-339 619,-309 708,-309 708,-339\"/>\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-327\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">linear2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"663.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256)</text>\n",
       "</g>\n",
       "<!-- 140432442521344&#45;&gt;140432442502784 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140432442521344&#45;&gt;140432442502784</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M663.5,-308.6924C663.5,-299.5067 663.5,-287.7245 663.5,-277.8312\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"667.0001,-277.703 663.5,-267.7031 660.0001,-277.7031 667.0001,-277.703\"/>\n",
       "</g>\n",
       "<!-- 140432442502736 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140432442502736</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"827,-267.5 732,-267.5 732,-248.5 827,-248.5 827,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"779.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140432442502736&#45;&gt;140432442502448 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140432442502736&#45;&gt;140432442502448</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M782.8937,-248.2615C786.257,-238.6102 791.5025,-223.558 795.7218,-211.4506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"799.1066,-212.3733 799.0923,-201.7785 792.4965,-210.0697 799.1066,-212.3733\"/>\n",
       "</g>\n",
       "<!-- 140432442502880 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140432442502880</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"824,-333.5 729,-333.5 729,-314.5 824,-314.5 824,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"776.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140432442502880&#45;&gt;140432442502736 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140432442502880&#45;&gt;140432442502736</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M776.9427,-314.2615C777.3769,-304.7077 778.0517,-289.8615 778.5992,-277.8183\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"782.0977,-277.9271 779.0555,-267.7785 775.105,-277.6092 782.0977,-277.9271\"/>\n",
       "</g>\n",
       "<!-- 140432442503072 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140432442503072</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"672,-399.5 571,-399.5 571,-380.5 672,-380.5 672,-399.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"621.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432442503072&#45;&gt;140432442502880 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140432442503072&#45;&gt;140432442502880</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M644.0383,-380.403C670.5161,-369.1286 714.6279,-350.3455 744.6069,-337.5803\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"746.3565,-340.6394 754.1859,-333.5015 743.6141,-334.199 746.3565,-340.6394\"/>\n",
       "</g>\n",
       "<!-- 140432442521152 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140432442521152</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"645,-471 556,-471 556,-441 645,-441 645,-471\"/>\n",
       "<text text-anchor=\"middle\" x=\"600.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">linear1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"600.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 140432442521152&#45;&gt;140432442503072 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140432442521152&#45;&gt;140432442503072</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M605.3706,-440.6924C608.3247,-431.408 612.1229,-419.4708 615.2914,-409.5127\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"618.7158,-410.2936 618.4127,-399.7031 612.0453,-408.1711 618.7158,-410.2936\"/>\n",
       "</g>\n",
       "<!-- 140432442503024 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140432442503024</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"800,-399.5 711,-399.5 711,-380.5 800,-380.5 800,-399.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 140432442503024&#45;&gt;140432442502880 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140432442503024&#45;&gt;140432442502880</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M758.5986,-380.2615C761.6695,-370.6102 766.4588,-355.558 770.3112,-343.4506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"773.6918,-344.369 773.3887,-333.7785 767.0213,-342.2465 773.6918,-344.369\"/>\n",
       "</g>\n",
       "<!-- 140432299032640 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140432299032640</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"848,-465.5 663,-465.5 663,-446.5 848,-446.5 848,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-453.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n",
       "</g>\n",
       "<!-- 140432299032640&#45;&gt;140432442503024 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140432299032640&#45;&gt;140432442503024</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M755.5,-446.2615C755.5,-436.7077 755.5,-421.8615 755.5,-409.8183\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"759.0001,-409.7784 755.5,-399.7785 752.0001,-409.7785 759.0001,-409.7784\"/>\n",
       "</g>\n",
       "<!-- 140432299032832 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>140432299032832</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"803,-531.5 708,-531.5 708,-512.5 803,-512.5 803,-531.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-519.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140432299032832&#45;&gt;140432299032640 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140432299032832&#45;&gt;140432299032640</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M755.5,-512.2615C755.5,-502.7077 755.5,-487.8615 755.5,-475.8183\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"759.0001,-475.7784 755.5,-465.7785 752.0001,-475.7785 759.0001,-475.7784\"/>\n",
       "</g>\n",
       "<!-- 140432299032928 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>140432299032928</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"839,-592 672,-592 672,-573 839,-573 839,-592\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-580\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140432299032928&#45;&gt;140432299032832 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140432299032928&#45;&gt;140432299032832</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M755.5,-572.7796C755.5,-564.5376 755.5,-552.4457 755.5,-542.129\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"759.0001,-541.8972 755.5,-531.8972 752.0001,-541.8973 759.0001,-541.8972\"/>\n",
       "</g>\n",
       "<!-- 140432299033024 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>140432299033024</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"666,-647 571,-647 571,-628 666,-628 666,-647\"/>\n",
       "<text text-anchor=\"middle\" x=\"618.5\" y=\"-635\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140432299033024&#45;&gt;140432299032928 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>140432299033024&#45;&gt;140432299032928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M642.3636,-627.9197C664.4269,-619.0622 697.4331,-605.8115 722.109,-595.9052\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"723.4741,-599.1287 731.4502,-592.155 720.8661,-592.6326 723.4741,-599.1287\"/>\n",
       "</g>\n",
       "<!-- 140432299033216 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>140432299033216</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"680,-707.5 513,-707.5 513,-688.5 680,-688.5 680,-707.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"596.5\" y=\"-695.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140432299033216&#45;&gt;140432299033024 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>140432299033216&#45;&gt;140432299033024</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M600.0347,-688.2796C603.0955,-679.8623 607.6166,-667.4295 611.4189,-656.973\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"614.7728,-657.9913 614.901,-647.3972 608.1942,-655.5991 614.7728,-657.9913\"/>\n",
       "</g>\n",
       "<!-- 140432299033312 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>140432299033312</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"507,-768 412,-768 412,-749 507,-749 507,-768\"/>\n",
       "<text text-anchor=\"middle\" x=\"459.5\" y=\"-756\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140432299033312&#45;&gt;140432299033216 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>140432299033312&#45;&gt;140432299033216</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M481.2081,-748.9136C503.955,-738.8684 539.8885,-723 565.5921,-711.6491\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"567.1597,-714.783 574.8935,-707.5416 564.3319,-708.3796 567.1597,-714.783\"/>\n",
       "</g>\n",
       "<!-- 140432299033504 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>140432299033504</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"521,-828.5 354,-828.5 354,-809.5 521,-809.5 521,-828.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.5\" y=\"-816.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140432299033504&#45;&gt;140432299033312 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>140432299033504&#45;&gt;140432299033312</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M441.0347,-809.2796C444.0955,-800.8623 448.6166,-788.4295 452.4189,-777.973\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"455.7728,-778.9913 455.901,-768.3972 449.1942,-776.5991 455.7728,-778.9913\"/>\n",
       "</g>\n",
       "<!-- 140432299033600 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>140432299033600</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"369,-889 184,-889 184,-870 369,-870 369,-889\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-877\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n",
       "</g>\n",
       "<!-- 140432299033600&#45;&gt;140432299033504 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>140432299033600&#45;&gt;140432299033504</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M302.0109,-869.9136C329.096,-859.7357 372.09,-843.5795 402.3688,-832.2015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"403.9787,-835.3355 412.1084,-828.5416 401.5163,-828.7829 403.9787,-835.3355\"/>\n",
       "</g>\n",
       "<!-- 140432299033792 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>140432299033792</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"324,-949.5 229,-949.5 229,-930.5 324,-930.5 324,-949.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-937.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140432299033792&#45;&gt;140432299033600 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>140432299033792&#45;&gt;140432299033600</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M276.5,-930.2796C276.5,-922.0376 276.5,-909.9457 276.5,-899.629\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.0001,-899.3972 276.5,-889.3972 273.0001,-899.3973 280.0001,-899.3972\"/>\n",
       "</g>\n",
       "<!-- 140432299033888 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>140432299033888</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"360,-1010 193,-1010 193,-991 360,-991 360,-1010\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-998\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140432299033888&#45;&gt;140432299033792 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>140432299033888&#45;&gt;140432299033792</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M276.5,-990.7796C276.5,-982.5376 276.5,-970.4457 276.5,-960.129\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.0001,-959.8972 276.5,-949.8972 273.0001,-959.8973 280.0001,-959.8972\"/>\n",
       "</g>\n",
       "<!-- 140432299033936 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>140432299033936</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"208,-1065 23,-1065 23,-1046 208,-1046 208,-1065\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-1053\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n",
       "</g>\n",
       "<!-- 140432299033936&#45;&gt;140432299033888 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>140432299033936&#45;&gt;140432299033888</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.5441,-1045.9197C169.8973,-1036.9171 209.5352,-1023.3762 238.6767,-1013.421\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.1761,-1016.6075 248.5077,-1010.0626 237.9131,-1009.9833 240.1761,-1016.6075\"/>\n",
       "</g>\n",
       "<!-- 140432299034224 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>140432299034224</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163,-1125.5 68,-1125.5 68,-1106.5 163,-1106.5 163,-1125.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-1113.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140432299034224&#45;&gt;140432299033936 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>140432299034224&#45;&gt;140432299033936</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M115.5,-1106.2796C115.5,-1098.0376 115.5,-1085.9457 115.5,-1075.629\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"119.0001,-1075.3972 115.5,-1065.3972 112.0001,-1075.3973 119.0001,-1075.3972\"/>\n",
       "</g>\n",
       "<!-- 140432299034272 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>140432299034272</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"199,-1186 32,-1186 32,-1167 199,-1167 199,-1186\"/>\n",
       "<text text-anchor=\"middle\" x=\"115.5\" y=\"-1174\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140432299034272&#45;&gt;140432299034224 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>140432299034272&#45;&gt;140432299034224</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M115.5,-1166.7796C115.5,-1158.5376 115.5,-1146.4457 115.5,-1136.129\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"119.0001,-1135.8972 115.5,-1125.8972 112.0001,-1135.8973 119.0001,-1135.8972\"/>\n",
       "</g>\n",
       "<!-- 140432299034416 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>140432299034416</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"107,-1241 6,-1241 6,-1222 107,-1222 107,-1241\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-1229\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299034416&#45;&gt;140432299034272 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>140432299034416&#45;&gt;140432299034272</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M66.777,-1221.9197C75.2176,-1214.0514 87.377,-1202.7164 97.4369,-1193.3385\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.0154,-1195.7198 104.9435,-1186.3408 95.2422,-1190.5995 100.0154,-1195.7198\"/>\n",
       "</g>\n",
       "<!-- 140432602200768 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>140432602200768</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"113,-1307 0,-1307 0,-1277 113,-1277 113,-1307\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-1295\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-1284\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (64, 3, 11, 11)</text>\n",
       "</g>\n",
       "<!-- 140432602200768&#45;&gt;140432299034416 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>140432602200768&#45;&gt;140432299034416</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M56.5,-1276.7333C56.5,-1269.0322 56.5,-1259.5977 56.5,-1251.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.0001,-1251.0864 56.5,-1241.0864 53.0001,-1251.0864 60.0001,-1251.0864\"/>\n",
       "</g>\n",
       "<!-- 140432299034368 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>140432299034368</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"226,-1241 125,-1241 125,-1222 226,-1222 226,-1241\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5\" y=\"-1229\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299034368&#45;&gt;140432299034272 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>140432299034368&#45;&gt;140432299034272</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M165.0488,-1221.9197C156.4651,-1214.0514 144.0997,-1202.7164 133.8693,-1193.3385\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"135.9721,-1190.5181 126.2355,-1186.3408 131.242,-1195.6782 135.9721,-1190.5181\"/>\n",
       "</g>\n",
       "<!-- 140432442520384 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>140432442520384</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"214,-1307 137,-1307 137,-1277 214,-1277 214,-1307\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5\" y=\"-1295\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"175.5\" y=\"-1284\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140432442520384&#45;&gt;140432299034368 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>140432442520384&#45;&gt;140432299034368</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M175.5,-1276.7333C175.5,-1269.0322 175.5,-1259.5977 175.5,-1251.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"179.0001,-1251.0864 175.5,-1241.0864 172.0001,-1251.0864 179.0001,-1251.0864\"/>\n",
       "</g>\n",
       "<!-- 140432299033696 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>140432299033696</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"327,-1065 226,-1065 226,-1046 327,-1046 327,-1065\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-1053\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299033696&#45;&gt;140432299033888 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>140432299033696&#45;&gt;140432299033888</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M276.5,-1045.9197C276.5,-1038.9083 276.5,-1029.1442 276.5,-1020.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.0001,-1020.3408 276.5,-1010.3408 273.0001,-1020.3409 280.0001,-1020.3408\"/>\n",
       "</g>\n",
       "<!-- 140432442520064 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>140432442520064</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"333,-1131 220,-1131 220,-1101 333,-1101 333,-1131\"/>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-1119\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"276.5\" y=\"-1108\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (128, 64, 5, 5)</text>\n",
       "</g>\n",
       "<!-- 140432442520064&#45;&gt;140432299033696 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>140432442520064&#45;&gt;140432299033696</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M276.5,-1100.7333C276.5,-1093.0322 276.5,-1083.5977 276.5,-1075.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.0001,-1075.0864 276.5,-1065.0864 273.0001,-1075.0864 280.0001,-1075.0864\"/>\n",
       "</g>\n",
       "<!-- 140432299034032 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>140432299034032</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"446,-1065 345,-1065 345,-1046 446,-1046 446,-1065\"/>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-1053\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299034032&#45;&gt;140432299033888 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>140432299034032&#45;&gt;140432299033888</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374.7718,-1045.9197C355.9465,-1037.219 327.9495,-1024.2792 306.6487,-1014.4343\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.9357,-1011.1734 297.39,-1010.155 304.9989,-1017.5276 307.9357,-1011.1734\"/>\n",
       "</g>\n",
       "<!-- 140432442520448 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>140432442520448</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"434,-1131 357,-1131 357,-1101 434,-1101 434,-1131\"/>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-1119\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"395.5\" y=\"-1108\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140432442520448&#45;&gt;140432299034032 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>140432442520448&#45;&gt;140432299034032</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M395.5,-1100.7333C395.5,-1093.0322 395.5,-1083.5977 395.5,-1075.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.0001,-1075.0864 395.5,-1065.0864 392.0001,-1075.0864 399.0001,-1075.0864\"/>\n",
       "</g>\n",
       "<!-- 140432299033552 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>140432299033552</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"488,-889 387,-889 387,-870 488,-870 488,-889\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.5\" y=\"-877\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299033552&#45;&gt;140432299033504 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>140432299033552&#45;&gt;140432299033504</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M437.5,-869.7796C437.5,-861.5376 437.5,-849.4457 437.5,-839.129\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"441.0001,-838.8972 437.5,-828.8972 434.0001,-838.8973 441.0001,-838.8972\"/>\n",
       "</g>\n",
       "<!-- 140432442520512 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>140432442520512</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"497,-955 378,-955 378,-925 497,-925 497,-955\"/>\n",
       "<text text-anchor=\"middle\" x=\"437.5\" y=\"-943\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"437.5\" y=\"-932\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256, 128, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140432442520512&#45;&gt;140432299033552 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>140432442520512&#45;&gt;140432299033552</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M437.5,-924.7333C437.5,-917.0322 437.5,-907.5977 437.5,-899.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"441.0001,-899.0864 437.5,-889.0864 434.0001,-899.0864 441.0001,-899.0864\"/>\n",
       "</g>\n",
       "<!-- 140432299033408 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>140432299033408</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"607,-889 506,-889 506,-870 607,-870 607,-889\"/>\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-877\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299033408&#45;&gt;140432299033504 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>140432299033408&#45;&gt;140432299033504</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M537.6441,-869.9136C518.1469,-860.0012 487.4965,-844.4184 465.2368,-833.1015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"466.768,-829.9536 456.2677,-828.5416 463.5956,-836.1935 466.768,-829.9536\"/>\n",
       "</g>\n",
       "<!-- 140432442520704 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>140432442520704</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"595,-955 518,-955 518,-925 595,-925 595,-955\"/>\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-943\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"556.5\" y=\"-932\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256)</text>\n",
       "</g>\n",
       "<!-- 140432442520704&#45;&gt;140432299033408 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>140432442520704&#45;&gt;140432299033408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M556.5,-924.7333C556.5,-917.0322 556.5,-907.5977 556.5,-899.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"560.0001,-899.0864 556.5,-889.0864 553.0001,-899.0864 560.0001,-899.0864\"/>\n",
       "</g>\n",
       "<!-- 140432299033264 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>140432299033264</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"647,-768 546,-768 546,-749 647,-749 647,-768\"/>\n",
       "<text text-anchor=\"middle\" x=\"596.5\" y=\"-756\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299033264&#45;&gt;140432299033216 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>140432299033264&#45;&gt;140432299033216</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M596.5,-748.7796C596.5,-740.5376 596.5,-728.4457 596.5,-718.129\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"600.0001,-717.8972 596.5,-707.8972 593.0001,-717.8973 600.0001,-717.8972\"/>\n",
       "</g>\n",
       "<!-- 140432442520576 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>140432442520576</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"658,-834 539,-834 539,-804 658,-804 658,-834\"/>\n",
       "<text text-anchor=\"middle\" x=\"598.5\" y=\"-822\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv4.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"598.5\" y=\"-811\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (128, 256, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140432442520576&#45;&gt;140432299033264 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>140432442520576&#45;&gt;140432299033264</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M597.9953,-803.7333C597.7407,-796.0322 597.4288,-786.5977 597.1559,-778.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"600.6455,-777.9653 596.8169,-768.0864 593.6493,-778.1966 600.6455,-777.9653\"/>\n",
       "</g>\n",
       "<!-- 140432299033120 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>140432299033120</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"766,-768 665,-768 665,-749 766,-749 766,-768\"/>\n",
       "<text text-anchor=\"middle\" x=\"715.5\" y=\"-756\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299033120&#45;&gt;140432299033216 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>140432299033120&#45;&gt;140432299033216</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M696.6441,-748.9136C677.1469,-739.0012 646.4965,-723.4184 624.2368,-712.1015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"625.768,-708.9536 615.2677,-707.5416 622.5956,-715.1935 625.768,-708.9536\"/>\n",
       "</g>\n",
       "<!-- 140432442520896 -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>140432442520896</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"754,-834 677,-834 677,-804 754,-804 754,-834\"/>\n",
       "<text text-anchor=\"middle\" x=\"715.5\" y=\"-822\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv4.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"715.5\" y=\"-811\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140432442520896&#45;&gt;140432299033120 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>140432442520896&#45;&gt;140432299033120</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M715.5,-803.7333C715.5,-796.0322 715.5,-786.5977 715.5,-778.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"719.0001,-778.0864 715.5,-768.0864 712.0001,-778.0864 719.0001,-778.0864\"/>\n",
       "</g>\n",
       "<!-- 140432299032976 -->\n",
       "<g id=\"node43\" class=\"node\">\n",
       "<title>140432299032976</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"806,-647 705,-647 705,-628 806,-628 806,-647\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-635\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299032976&#45;&gt;140432299032928 -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>140432299032976&#45;&gt;140432299032928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M755.5,-627.9197C755.5,-620.9083 755.5,-611.1442 755.5,-602.4652\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"759.0001,-602.3408 755.5,-592.3408 752.0001,-602.3409 759.0001,-602.3408\"/>\n",
       "</g>\n",
       "<!-- 140432442520768 -->\n",
       "<g id=\"node44\" class=\"node\">\n",
       "<title>140432442520768</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"817,-713 698,-713 698,-683 817,-683 817,-713\"/>\n",
       "<text text-anchor=\"middle\" x=\"757.5\" y=\"-701\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv5.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"757.5\" y=\"-690\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (128, 128, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140432442520768&#45;&gt;140432299032976 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>140432442520768&#45;&gt;140432299032976</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M756.9953,-682.7333C756.7407,-675.0322 756.4288,-665.5977 756.1559,-657.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"759.6455,-656.9653 755.8169,-647.0864 752.6493,-657.1966 759.6455,-656.9653\"/>\n",
       "</g>\n",
       "<!-- 140432299032736 -->\n",
       "<g id=\"node45\" class=\"node\">\n",
       "<title>140432299032736</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"925,-647 824,-647 824,-628 925,-628 925,-647\"/>\n",
       "<text text-anchor=\"middle\" x=\"874.5\" y=\"-635\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299032736&#45;&gt;140432299032928 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>140432299032736&#45;&gt;140432299032928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M853.7718,-627.9197C834.9465,-619.219 806.9495,-606.2792 785.6487,-596.4343\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"786.9357,-593.1734 776.39,-592.155 783.9989,-599.5276 786.9357,-593.1734\"/>\n",
       "</g>\n",
       "<!-- 140432442521088 -->\n",
       "<g id=\"node46\" class=\"node\">\n",
       "<title>140432442521088</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"913,-713 836,-713 836,-683 913,-683 913,-713\"/>\n",
       "<text text-anchor=\"middle\" x=\"874.5\" y=\"-701\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">conv5.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"874.5\" y=\"-690\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140432442521088&#45;&gt;140432299032736 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>140432442521088&#45;&gt;140432299032736</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M874.5,-682.7333C874.5,-675.0322 874.5,-665.5977 874.5,-657.3414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"878.0001,-657.0864 874.5,-647.0864 871.0001,-657.0864 878.0001,-657.0864\"/>\n",
       "</g>\n",
       "<!-- 140432442502976 -->\n",
       "<g id=\"node47\" class=\"node\">\n",
       "<title>140432442502976</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"889,-399.5 818,-399.5 818,-380.5 889,-380.5 889,-399.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"853.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140432442502976&#45;&gt;140432442502880 -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>140432442502976&#45;&gt;140432442502880</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M842.1384,-380.2615C829.8988,-369.7704 810.2137,-352.8974 795.5892,-340.3622\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"797.5283,-337.4144 787.6579,-333.5639 792.9727,-342.7293 797.5283,-337.4144\"/>\n",
       "</g>\n",
       "<!-- 140432299032880 -->\n",
       "<g id=\"node48\" class=\"node\">\n",
       "<title>140432299032880</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"967,-465.5 866,-465.5 866,-446.5 967,-446.5 967,-465.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"916.5\" y=\"-453.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432299032880&#45;&gt;140432442502976 -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>140432299032880&#45;&gt;140432442502976</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M907.2041,-446.2615C897.4332,-436.0253 881.863,-419.7137 869.9979,-407.2835\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"872.2705,-404.5954 862.834,-399.7785 867.207,-409.4287 872.2705,-404.5954\"/>\n",
       "</g>\n",
       "<!-- 140432442521216 -->\n",
       "<g id=\"node49\" class=\"node\">\n",
       "<title>140432442521216</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"967,-537 866,-537 866,-507 967,-507 967,-537\"/>\n",
       "<text text-anchor=\"middle\" x=\"916.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">linear1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"916.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1024, 4608)</text>\n",
       "</g>\n",
       "<!-- 140432442521216&#45;&gt;140432299032880 -->\n",
       "<g id=\"edge47\" class=\"edge\">\n",
       "<title>140432442521216&#45;&gt;140432299032880</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M916.5,-506.6924C916.5,-497.5067 916.5,-485.7245 916.5,-475.8312\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"920.0001,-475.703 916.5,-465.7031 913.0001,-475.7031 920.0001,-475.703\"/>\n",
       "</g>\n",
       "<!-- 140432442502688 -->\n",
       "<g id=\"node50\" class=\"node\">\n",
       "<title>140432442502688</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"916,-267.5 845,-267.5 845,-248.5 916,-248.5 916,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"880.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140432442502688&#45;&gt;140432442502448 -->\n",
       "<g id=\"edge48\" class=\"edge\">\n",
       "<title>140432442502688&#45;&gt;140432442502448</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M868.9908,-248.2615C856.5923,-237.7704 836.6515,-220.8974 821.8371,-208.3622\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"823.6975,-205.3515 813.8028,-201.5639 819.1759,-210.6952 823.6975,-205.3515\"/>\n",
       "</g>\n",
       "<!-- 140432442503120 -->\n",
       "<g id=\"node51\" class=\"node\">\n",
       "<title>140432442503120</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"986,-333.5 885,-333.5 885,-314.5 986,-314.5 986,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"935.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432442503120&#45;&gt;140432442502688 -->\n",
       "<g id=\"edge49\" class=\"edge\">\n",
       "<title>140432442503120&#45;&gt;140432442502688</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M927.3846,-314.2615C918.9357,-304.1228 905.5198,-288.0238 895.1997,-275.6397\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"897.7394,-273.2201 888.6487,-267.7785 892.3618,-277.7014 897.7394,-273.2201\"/>\n",
       "</g>\n",
       "<!-- 140432442520960 -->\n",
       "<g id=\"node52\" class=\"node\">\n",
       "<title>140432442520960</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1008,-405 907,-405 907,-375 1008,-375 1008,-405\"/>\n",
       "<text text-anchor=\"middle\" x=\"957.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">linear2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"957.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (256, 1024)</text>\n",
       "</g>\n",
       "<!-- 140432442520960&#45;&gt;140432442503120 -->\n",
       "<g id=\"edge50\" class=\"edge\">\n",
       "<title>140432442520960&#45;&gt;140432442503120</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M952.3975,-374.6924C949.2697,-365.3092 945.2388,-353.2165 941.8985,-343.1956\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"945.2171,-342.0831 938.7344,-333.7031 938.5763,-344.2967 945.2171,-342.0831\"/>\n",
       "</g>\n",
       "<!-- 140432442502496 -->\n",
       "<g id=\"node53\" class=\"node\">\n",
       "<title>140432442502496</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"970,-141 899,-141 899,-122 970,-122 970,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"934.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140432442502496&#45;&gt;140432442502544 -->\n",
       "<g id=\"edge51\" class=\"edge\">\n",
       "<title>140432442502496&#45;&gt;140432442502544</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M912.0299,-121.9197C891.4388,-113.1406 860.7254,-100.0457 837.5599,-90.1689\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"838.7169,-86.8575 828.1454,-86.155 835.9715,-93.2966 838.7169,-86.8575\"/>\n",
       "</g>\n",
       "<!-- 140432442502928 -->\n",
       "<g id=\"node54\" class=\"node\">\n",
       "<title>140432442502928</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1013,-201.5 912,-201.5 912,-182.5 1013,-182.5 1013,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"962.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140432442502928&#45;&gt;140432442502496 -->\n",
       "<g id=\"edge52\" class=\"edge\">\n",
       "<title>140432442502928&#45;&gt;140432442502496</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M958.0013,-182.2796C954.0651,-173.7746 948.2316,-161.17 943.3614,-150.6469\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"946.457,-149.0024 939.0805,-141.3972 940.1044,-151.9425 946.457,-149.0024\"/>\n",
       "</g>\n",
       "<!-- 140432442521408 -->\n",
       "<g id=\"node55\" class=\"node\">\n",
       "<title>140432442521408</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1035,-273 934,-273 934,-243 1035,-243 1035,-273\"/>\n",
       "<text text-anchor=\"middle\" x=\"984.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">linear3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"984.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (20, 256)</text>\n",
       "</g>\n",
       "<!-- 140432442521408&#45;&gt;140432442502928 -->\n",
       "<g id=\"edge53\" class=\"edge\">\n",
       "<title>140432442521408&#45;&gt;140432442502928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M979.3975,-242.6924C976.2697,-233.3092 972.2388,-221.2165 968.8985,-211.1956\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"972.2171,-210.0831 965.7344,-201.7031 965.5763,-212.2967 972.2171,-210.0831\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fb8f9d9acd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__() # this line must be done first\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=11,stride=4,padding=2)   \n",
    "        self.conv2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256,out_channels=128,kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1)\n",
    "        \n",
    "        self.linear1 = nn.Linear(4608,1024)\n",
    "        self.linear2 = nn.Linear(1024,256)\n",
    "        self.linear3 = nn.Linear(256,20)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2)     \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 1~3\n",
    "        x = self.maxpool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # 4~6\n",
    "        x = self.maxpool(F.relu(self.conv2(x)))\n",
    "        # 7-8\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # 9~10\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # 11~12\n",
    "        x = F.relu(self.conv5(x))\n",
    "        # 13\n",
    "        x = self.maxpool(x)\n",
    "        # 14\n",
    "        x = flatten(x)\n",
    "        # 15~16\n",
    "        x = F.relu(self.linear1(x))\n",
    "        # 17~18\n",
    "        x = F.relu(self.linear2(x))\n",
    "        # 19\n",
    "        x = self.linear3(x)\n",
    "        return x \n",
    "\n",
    "x = torch.randn(4, 3, 224, 224)\n",
    "model = TestModel()\n",
    "\n",
    "make_dot(model(x), params=dict(model.named_parameters()))\n",
    "# 可以將畫出來的圖與助教提供的圖對比看看是否一樣或十分相似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0b33c",
   "metadata": {},
   "source": [
    "### 2.3 使用 nn.Sequential 建立模型\n",
    "```nn.Sequential``` 的不同之處在於可以直接從一系列的 layer 建立模型，不需定義 ```__init__``` 也不用定義 ```forward``` ，會自動依序用每一層進行 forward ，相對地，其成員皆需有 ```forward``` 可以呼叫。\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea9f4ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass Flatten(nn.Module):\\n    def forward(self, x):\\n        return flatten(x)\\n\\nmodel = None\\nmodel = nn.Sequential( \\n            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=11,stride=4,padding=2),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=3,stride=2),      \\n            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,padding=2),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=3,stride=2),  \\n            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1),\\n            nn.ReLU(),        \\n            nn.Conv2d(in_channels=256,out_channels=128,kernel_size=3,padding=1),\\n            nn.ReLU(),            \\n            nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1),\\n            nn.ReLU(),                  \\n            nn.MaxPool2d(kernel_size=3,stride=2), \\n            Flatten(),\\n            nn.Linear(4608,1024),\\n            nn.ReLU(),       \\n            nn.Linear(1024,256),\\n            nn.ReLU(),       \\n            nn.Linear(256,20)\\n        )\\n    \\nx = torch.randn(4, 3, 224, 224)\\nmake_dot(model(x), params=dict(model.named_parameters()))\\n# 可以將畫出來的圖與助教提供的圖對比看看是否一樣或十分相似\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap the flatten function\n",
    "'''\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "model = None\n",
    "model = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),      \n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),  \n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),        \n",
    "            nn.Conv2d(in_channels=256,out_channels=128,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),            \n",
    "            nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),                  \n",
    "            nn.MaxPool2d(kernel_size=3,stride=2), \n",
    "            Flatten(),\n",
    "            nn.Linear(4608,1024),\n",
    "            nn.ReLU(),       \n",
    "            nn.Linear(1024,256),\n",
    "            nn.ReLU(),       \n",
    "            nn.Linear(256,20)\n",
    "        )\n",
    "    \n",
    "x = torch.randn(4, 3, 224, 224)\n",
    "make_dot(model(x), params=dict(model.named_parameters()))\n",
    "# 可以將畫出來的圖與助教提供的圖對比看看是否一樣或十分相似\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2cc27",
   "metadata": {},
   "source": [
    "### 2.4 自行設計模型\n",
    "請使用上述任一種方式設計自己的模型(實體化後的模型名稱為 ```mymodel```)，並解釋自己的設計。最後的分類為 20 個類別。\n",
    "\n",
    "## **不可以直接呼叫```torchvision.models```中已經寫好的模型，但可以照著論文中的模型架構手刻出來**\n",
    "\n",
    "## **不可以使用預訓練過的模型權重作為初始狀態，也就是不能用預訓練的模型再 fine-tune**\n",
    "\n",
    "請完成以下被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d94b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel = None\n",
    "#x = torch.randn(4, 3, 224, 224)\n",
    "#make_dot(mymodel(x), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bae4f0",
   "metadata": {},
   "source": [
    "#### 解釋寫在這裡\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a37fb",
   "metadata": {},
   "source": [
    "## 3 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e0efa",
   "metadata": {},
   "source": [
    "### 3.1 設定 loss function 以及 optimizer\n",
    "+ 對於分類問題，通常使用 cross entropy 就足夠\n",
    "+ Optimizer 常用的有 SGD, Adam 等等\n",
    "\n",
    "請完成以下 ? 處以及被註解框起來的區域。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63336950",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters() ,lr=LR)\n",
    "optimizer = torch.optim.SGD(model.parameters() ,lr=LR,momentum=MOMENTUM,weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b33ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這個 cell 不用填\n",
    "\n",
    "# helper functions\n",
    "def accuracy(outputs, targets):\n",
    "    \"\"\"Compute accuracy\"\"\"\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    pred = outputs.argmax(-1)\n",
    "    correct = pred.eq(targets)\n",
    "    acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "    return acc\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"A Meter that records numbers and compute the average.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0.0\n",
    "        self.avg = 0.0\n",
    "        self.sum = 0.0\n",
    "        self.count = 0.0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17783103",
   "metadata": {},
   "source": [
    "### 3.2 開始訓練\n",
    "流程：\n",
    "\n",
    "訓練階段，在一個 iteration 中，\n",
    "1. 取出 batch 中的資料\n",
    "2. 由模型預測分類結果 (forward)\n",
    "3. 計算 loss \n",
    "4. 清空梯度\n",
    "5. backward 計算梯度\n",
    "6. 更新模型參數\n",
    "\n",
    "重複以上動作直到所有 batch 迭代完成後，進入測試階段，使用測試集測試模型表現，計算準確度。\n",
    "\n",
    "到這裡是一個 epoch 的動作，重複直到設定的 epoch 數量後結束。\n",
    "\n",
    "以下會把每一個 epoch 的訓練和測試部份寫成兩個 function，請完成 ? 的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "576a5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loader, criterion, optimizer):\n",
    "    \"\"\"This function trains for 1 epoch and returns the epoch loss and accuracy.\"\"\"\n",
    "    # recorders\n",
    "    loss_m = AverageMeter()\n",
    "    acc_m = AverageMeter()\n",
    "    \n",
    "    model.train() # Set model to training mode\n",
    "    \n",
    "    for idx, (imgs, labels) in enumerate(loader): # load data\n",
    "        # put the data to correct device\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        # model forward\n",
    "        outputs = model(imgs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # clear optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward to calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "          \n",
    "        # accuracy\n",
    "        acc = accuracy(outputs, labels)\n",
    "        \n",
    "        # record loss and acc\n",
    "        loss_m.update(loss.item(), imgs.size(0))\n",
    "        acc_m.update(acc.item(), imgs.size(0))\n",
    "        \n",
    "        # logging\n",
    "        if (idx >= 0) and (idx % PRINT_FREQ == 0):\n",
    "            print(\"[{:3d}/{}] Train Loss {:.3f} Acc {:.3f}\".format(\n",
    "                idx, len(loader), loss_m.val, acc_m.val\n",
    "            ))\n",
    "        \n",
    "    return loss_m.avg, acc_m.avg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d615c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, criterion):\n",
    "    \"\"\"This function tests the model on the test set.\"\"\"\n",
    "    # recorders\n",
    "    loss_m = AverageMeter()\n",
    "    out_list, y_list = [], []\n",
    "    \n",
    "    model.eval() # set model to eval mode\n",
    "    \n",
    "    with torch.no_grad(): # no need to compute gradient when testing\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # model forward\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            # compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            y_list.append(labels)\n",
    "            out_list.append(outputs)\n",
    "            loss_m.update(loss.item())\n",
    "        \n",
    "        # concat all predictions and answers to compute accuracy\n",
    "        pred = torch.cat(out_list)\n",
    "        y = torch.cat(y_list)\n",
    "        acc = accuracy(outputs, labels)\n",
    "    \n",
    "    return loss_m.avg, acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd57a5f",
   "metadata": {},
   "source": [
    "#### Let's GOOOOOO\n",
    "\n",
    "請完成以下 ? 處，並執行這個 cell 以開始訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94c1ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 1 ----------------\n",
      "[  0/91] Train Loss 3.050 Acc 0.000\n",
      "[ 10/91] Train Loss 3.019 Acc 0.000\n",
      "[ 20/91] Train Loss 3.010 Acc 0.000\n",
      "[ 30/91] Train Loss 2.962 Acc 0.000\n",
      "[ 40/91] Train Loss 2.956 Acc 0.000\n",
      "[ 50/91] Train Loss 3.057 Acc 0.000\n",
      "[ 60/91] Train Loss 3.062 Acc 0.000\n",
      "[ 70/91] Train Loss 3.049 Acc 0.000\n",
      "[ 80/91] Train Loss 3.063 Acc 0.000\n",
      "[ 90/91] Train Loss 3.030 Acc 0.000\n",
      "Epoch   1/40 Train Loss 3.017 Acc 0.014\n",
      "---------------- Testing ----------------\n",
      "Epoch   1/40 Test Loss 2.995 Acc 0.000\n",
      "---------------- Epoch 2 ----------------\n",
      "[  0/91] Train Loss 3.052 Acc 0.000\n",
      "[ 10/91] Train Loss 2.994 Acc 0.000\n",
      "[ 20/91] Train Loss 2.999 Acc 0.000\n",
      "[ 30/91] Train Loss 2.959 Acc 0.000\n",
      "[ 40/91] Train Loss 2.961 Acc 0.000\n",
      "[ 50/91] Train Loss 3.053 Acc 0.000\n",
      "[ 60/91] Train Loss 3.057 Acc 0.000\n",
      "[ 70/91] Train Loss 3.055 Acc 0.000\n",
      "[ 80/91] Train Loss 3.070 Acc 0.000\n",
      "[ 90/91] Train Loss 3.014 Acc 0.000\n",
      "Epoch   2/40 Train Loss 3.013 Acc 0.003\n",
      "---------------- Testing ----------------\n",
      "Epoch   2/40 Test Loss 2.994 Acc 0.000\n",
      "---------------- Epoch 3 ----------------\n",
      "[  0/91] Train Loss 3.059 Acc 0.000\n",
      "[ 10/91] Train Loss 2.975 Acc 0.000\n",
      "[ 20/91] Train Loss 2.990 Acc 0.000\n",
      "[ 30/91] Train Loss 2.959 Acc 0.000\n",
      "[ 40/91] Train Loss 2.967 Acc 0.000\n",
      "[ 50/91] Train Loss 3.052 Acc 0.000\n",
      "[ 60/91] Train Loss 3.053 Acc 0.000\n",
      "[ 70/91] Train Loss 3.060 Acc 0.000\n",
      "[ 80/91] Train Loss 3.076 Acc 0.000\n",
      "[ 90/91] Train Loss 2.998 Acc 0.000\n",
      "Epoch   3/40 Train Loss 3.012 Acc 0.000\n",
      "---------------- Testing ----------------\n",
      "Epoch   3/40 Test Loss 2.992 Acc 0.000\n",
      "---------------- Epoch 4 ----------------\n",
      "[  0/91] Train Loss 3.066 Acc 0.000\n",
      "[ 10/91] Train Loss 2.959 Acc 0.000\n",
      "[ 20/91] Train Loss 2.982 Acc 0.000\n",
      "[ 30/91] Train Loss 2.958 Acc 0.000\n",
      "[ 40/91] Train Loss 2.972 Acc 0.000\n",
      "[ 50/91] Train Loss 3.051 Acc 0.000\n",
      "[ 60/91] Train Loss 3.050 Acc 0.000\n",
      "[ 70/91] Train Loss 3.065 Acc 0.000\n",
      "[ 80/91] Train Loss 3.082 Acc 0.000\n",
      "[ 90/91] Train Loss 2.984 Acc 0.000\n",
      "Epoch   4/40 Train Loss 3.010 Acc 0.008\n",
      "---------------- Testing ----------------\n",
      "Epoch   4/40 Test Loss 2.991 Acc 0.000\n",
      "---------------- Epoch 5 ----------------\n",
      "[  0/91] Train Loss 3.072 Acc 0.000\n",
      "[ 10/91] Train Loss 2.943 Acc 1.000\n",
      "[ 20/91] Train Loss 2.974 Acc 0.000\n",
      "[ 30/91] Train Loss 2.958 Acc 0.000\n",
      "[ 40/91] Train Loss 2.976 Acc 0.000\n",
      "[ 50/91] Train Loss 3.051 Acc 0.000\n",
      "[ 60/91] Train Loss 3.047 Acc 0.000\n",
      "[ 70/91] Train Loss 3.070 Acc 0.000\n",
      "[ 80/91] Train Loss 3.088 Acc 0.000\n",
      "[ 90/91] Train Loss 2.971 Acc 0.000\n",
      "Epoch   5/40 Train Loss 3.009 Acc 0.068\n",
      "---------------- Testing ----------------\n",
      "Epoch   5/40 Test Loss 2.990 Acc 0.000\n",
      "---------------- Epoch 6 ----------------\n",
      "[  0/91] Train Loss 3.078 Acc 0.000\n",
      "[ 10/91] Train Loss 2.928 Acc 1.000\n",
      "[ 20/91] Train Loss 2.967 Acc 0.000\n",
      "[ 30/91] Train Loss 2.957 Acc 0.000\n",
      "[ 40/91] Train Loss 2.981 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.044 Acc 0.000\n",
      "[ 70/91] Train Loss 3.075 Acc 0.000\n",
      "[ 80/91] Train Loss 3.094 Acc 0.000\n",
      "[ 90/91] Train Loss 2.958 Acc 0.000\n",
      "Epoch   6/40 Train Loss 3.008 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch   6/40 Test Loss 2.990 Acc 0.000\n",
      "---------------- Epoch 7 ----------------\n",
      "[  0/91] Train Loss 3.084 Acc 0.000\n",
      "[ 10/91] Train Loss 2.914 Acc 1.000\n",
      "[ 20/91] Train Loss 2.961 Acc 0.000\n",
      "[ 30/91] Train Loss 2.957 Acc 0.000\n",
      "[ 40/91] Train Loss 2.985 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.041 Acc 0.000\n",
      "[ 70/91] Train Loss 3.080 Acc 0.000\n",
      "[ 80/91] Train Loss 3.100 Acc 0.000\n",
      "[ 90/91] Train Loss 2.946 Acc 0.000\n",
      "Epoch   7/40 Train Loss 3.007 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch   7/40 Test Loss 2.989 Acc 0.000\n",
      "---------------- Epoch 8 ----------------\n",
      "[  0/91] Train Loss 3.090 Acc 0.000\n",
      "[ 10/91] Train Loss 2.901 Acc 1.000\n",
      "[ 20/91] Train Loss 2.954 Acc 0.000\n",
      "[ 30/91] Train Loss 2.957 Acc 0.000\n",
      "[ 40/91] Train Loss 2.990 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.039 Acc 0.000\n",
      "[ 70/91] Train Loss 3.084 Acc 0.000\n",
      "[ 80/91] Train Loss 3.105 Acc 0.000\n",
      "[ 90/91] Train Loss 2.936 Acc 0.000\n",
      "Epoch   8/40 Train Loss 3.006 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch   8/40 Test Loss 2.988 Acc 0.000\n",
      "---------------- Epoch 9 ----------------\n",
      "[  0/91] Train Loss 3.095 Acc 0.000\n",
      "[ 10/91] Train Loss 2.888 Acc 1.000\n",
      "[ 20/91] Train Loss 2.949 Acc 0.000\n",
      "[ 30/91] Train Loss 2.957 Acc 0.000\n",
      "[ 40/91] Train Loss 2.994 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.037 Acc 0.000\n",
      "[ 70/91] Train Loss 3.089 Acc 0.000\n",
      "[ 80/91] Train Loss 3.111 Acc 0.000\n",
      "[ 90/91] Train Loss 2.925 Acc 0.000\n",
      "Epoch   9/40 Train Loss 3.006 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch   9/40 Test Loss 2.987 Acc 0.000\n",
      "---------------- Epoch 10 ----------------\n",
      "[  0/91] Train Loss 3.101 Acc 0.000\n",
      "[ 10/91] Train Loss 2.876 Acc 1.000\n",
      "[ 20/91] Train Loss 2.943 Acc 0.000\n",
      "[ 30/91] Train Loss 2.956 Acc 0.000\n",
      "[ 40/91] Train Loss 2.999 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.035 Acc 0.000\n",
      "[ 70/91] Train Loss 3.094 Acc 0.000\n",
      "[ 80/91] Train Loss 3.116 Acc 0.000\n",
      "[ 90/91] Train Loss 2.915 Acc 0.000\n",
      "Epoch  10/40 Train Loss 3.005 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  10/40 Test Loss 2.987 Acc 0.000\n",
      "---------------- Epoch 11 ----------------\n",
      "[  0/91] Train Loss 3.106 Acc 0.000\n",
      "[ 10/91] Train Loss 2.865 Acc 1.000\n",
      "[ 20/91] Train Loss 2.938 Acc 0.000\n",
      "[ 30/91] Train Loss 2.956 Acc 0.000\n",
      "[ 40/91] Train Loss 3.003 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.033 Acc 0.000\n",
      "[ 70/91] Train Loss 3.097 Acc 0.000\n",
      "[ 80/91] Train Loss 3.120 Acc 0.000\n",
      "[ 90/91] Train Loss 2.906 Acc 0.000\n",
      "Epoch  11/40 Train Loss 3.004 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  11/40 Test Loss 2.986 Acc 0.000\n",
      "---------------- Epoch 12 ----------------\n",
      "[  0/91] Train Loss 3.110 Acc 0.000\n",
      "[ 10/91] Train Loss 2.855 Acc 1.000\n",
      "[ 20/91] Train Loss 2.934 Acc 0.000\n",
      "[ 30/91] Train Loss 2.956 Acc 0.000\n",
      "[ 40/91] Train Loss 3.006 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.031 Acc 0.000\n",
      "[ 70/91] Train Loss 3.101 Acc 0.000\n",
      "[ 80/91] Train Loss 3.125 Acc 0.000\n",
      "[ 90/91] Train Loss 2.898 Acc 0.000\n",
      "Epoch  12/40 Train Loss 3.004 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  12/40 Test Loss 2.986 Acc 0.000\n",
      "---------------- Epoch 13 ----------------\n",
      "[  0/91] Train Loss 3.115 Acc 0.000\n",
      "[ 10/91] Train Loss 2.845 Acc 1.000\n",
      "[ 20/91] Train Loss 2.929 Acc 0.000\n",
      "[ 30/91] Train Loss 2.955 Acc 0.000\n",
      "[ 40/91] Train Loss 3.009 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.030 Acc 0.000\n",
      "[ 70/91] Train Loss 3.105 Acc 0.000\n",
      "[ 80/91] Train Loss 3.129 Acc 0.000\n",
      "[ 90/91] Train Loss 2.890 Acc 0.000\n",
      "Epoch  13/40 Train Loss 3.003 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  13/40 Test Loss 2.985 Acc 0.000\n",
      "---------------- Epoch 14 ----------------\n",
      "[  0/91] Train Loss 3.119 Acc 0.000\n",
      "[ 10/91] Train Loss 2.836 Acc 1.000\n",
      "[ 20/91] Train Loss 2.925 Acc 0.000\n",
      "[ 30/91] Train Loss 2.954 Acc 0.000\n",
      "[ 40/91] Train Loss 3.013 Acc 0.000\n",
      "[ 50/91] Train Loss 3.050 Acc 0.000\n",
      "[ 60/91] Train Loss 3.028 Acc 0.000\n",
      "[ 70/91] Train Loss 3.109 Acc 0.000\n",
      "[ 80/91] Train Loss 3.133 Acc 0.000\n",
      "[ 90/91] Train Loss 2.883 Acc 0.000\n",
      "Epoch  14/40 Train Loss 3.003 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  14/40 Test Loss 2.985 Acc 0.000\n",
      "---------------- Epoch 15 ----------------\n",
      "[  0/91] Train Loss 3.122 Acc 0.000\n",
      "[ 10/91] Train Loss 2.827 Acc 1.000\n",
      "[ 20/91] Train Loss 2.921 Acc 0.000\n",
      "[ 30/91] Train Loss 2.954 Acc 0.000\n",
      "[ 40/91] Train Loss 3.016 Acc 0.000\n",
      "[ 50/91] Train Loss 3.051 Acc 0.000\n",
      "[ 60/91] Train Loss 3.025 Acc 0.000\n",
      "[ 70/91] Train Loss 3.113 Acc 0.000\n",
      "[ 80/91] Train Loss 3.137 Acc 0.000\n",
      "[ 90/91] Train Loss 2.875 Acc 0.000\n",
      "Epoch  15/40 Train Loss 3.003 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  15/40 Test Loss 2.984 Acc 0.000\n",
      "---------------- Epoch 16 ----------------\n",
      "[  0/91] Train Loss 3.127 Acc 0.000\n",
      "[ 10/91] Train Loss 2.819 Acc 1.000\n",
      "[ 20/91] Train Loss 2.917 Acc 0.000\n",
      "[ 30/91] Train Loss 2.954 Acc 0.000\n",
      "[ 40/91] Train Loss 3.020 Acc 0.000\n",
      "[ 50/91] Train Loss 3.051 Acc 0.000\n",
      "[ 60/91] Train Loss 3.024 Acc 0.000\n",
      "[ 70/91] Train Loss 3.116 Acc 0.000\n",
      "[ 80/91] Train Loss 3.140 Acc 0.000\n",
      "[ 90/91] Train Loss 2.869 Acc 0.000\n",
      "Epoch  16/40 Train Loss 3.002 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  16/40 Test Loss 2.984 Acc 0.000\n",
      "---------------- Epoch 17 ----------------\n",
      "[  0/91] Train Loss 3.129 Acc 0.000\n",
      "[ 10/91] Train Loss 2.810 Acc 1.000\n",
      "[ 20/91] Train Loss 2.912 Acc 0.000\n",
      "[ 30/91] Train Loss 2.953 Acc 0.000\n",
      "[ 40/91] Train Loss 3.023 Acc 0.000\n",
      "[ 50/91] Train Loss 3.051 Acc 0.000\n",
      "[ 60/91] Train Loss 3.023 Acc 0.000\n",
      "[ 70/91] Train Loss 3.119 Acc 0.000\n",
      "[ 80/91] Train Loss 3.144 Acc 0.000\n",
      "[ 90/91] Train Loss 2.863 Acc 0.000\n",
      "Epoch  17/40 Train Loss 3.002 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  17/40 Test Loss 2.983 Acc 0.000\n",
      "---------------- Epoch 18 ----------------\n",
      "[  0/91] Train Loss 3.133 Acc 0.000\n",
      "[ 10/91] Train Loss 2.802 Acc 1.000\n",
      "[ 20/91] Train Loss 2.909 Acc 0.000\n",
      "[ 30/91] Train Loss 2.952 Acc 0.000\n",
      "[ 40/91] Train Loss 3.026 Acc 0.000\n",
      "[ 50/91] Train Loss 3.052 Acc 0.000\n",
      "[ 60/91] Train Loss 3.021 Acc 0.000\n",
      "[ 70/91] Train Loss 3.122 Acc 0.000\n",
      "[ 80/91] Train Loss 3.147 Acc 0.000\n",
      "[ 90/91] Train Loss 2.858 Acc 0.000\n",
      "Epoch  18/40 Train Loss 3.001 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  18/40 Test Loss 2.982 Acc 0.000\n",
      "---------------- Epoch 19 ----------------\n",
      "[  0/91] Train Loss 3.136 Acc 0.000\n",
      "[ 10/91] Train Loss 2.795 Acc 1.000\n",
      "[ 20/91] Train Loss 2.906 Acc 0.000\n",
      "[ 30/91] Train Loss 2.948 Acc 0.000\n",
      "[ 40/91] Train Loss 3.030 Acc 0.000\n",
      "[ 50/91] Train Loss 3.052 Acc 0.000\n",
      "[ 60/91] Train Loss 3.020 Acc 0.000\n",
      "[ 70/91] Train Loss 3.125 Acc 0.000\n",
      "[ 80/91] Train Loss 3.151 Acc 0.000\n",
      "[ 90/91] Train Loss 2.850 Acc 0.000\n",
      "Epoch  19/40 Train Loss 3.001 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  19/40 Test Loss 2.981 Acc 0.000\n",
      "---------------- Epoch 20 ----------------\n",
      "[  0/91] Train Loss 3.139 Acc 0.000\n",
      "[ 10/91] Train Loss 2.787 Acc 1.000\n",
      "[ 20/91] Train Loss 2.902 Acc 0.000\n",
      "[ 30/91] Train Loss 2.948 Acc 0.000\n",
      "[ 40/91] Train Loss 3.033 Acc 0.000\n",
      "[ 50/91] Train Loss 3.052 Acc 0.000\n",
      "[ 60/91] Train Loss 3.019 Acc 0.000\n",
      "[ 70/91] Train Loss 3.128 Acc 0.000\n",
      "[ 80/91] Train Loss 3.154 Acc 0.000\n",
      "[ 90/91] Train Loss 2.847 Acc 0.000\n",
      "Epoch  20/40 Train Loss 3.000 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  20/40 Test Loss 2.981 Acc 0.000\n",
      "---------------- Epoch 21 ----------------\n",
      "[  0/91] Train Loss 3.141 Acc 0.000\n",
      "[ 10/91] Train Loss 2.778 Acc 1.000\n",
      "[ 20/91] Train Loss 2.898 Acc 0.000\n",
      "[ 30/91] Train Loss 2.944 Acc 0.000\n",
      "[ 40/91] Train Loss 3.035 Acc 0.000\n",
      "[ 50/91] Train Loss 3.053 Acc 0.000\n",
      "[ 60/91] Train Loss 3.016 Acc 0.000\n",
      "[ 70/91] Train Loss 3.130 Acc 0.000\n",
      "[ 80/91] Train Loss 3.154 Acc 0.000\n",
      "[ 90/91] Train Loss 2.843 Acc 0.000\n",
      "Epoch  21/40 Train Loss 3.000 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  21/40 Test Loss 2.980 Acc 0.000\n",
      "---------------- Epoch 22 ----------------\n",
      "[  0/91] Train Loss 3.145 Acc 0.000\n",
      "[ 10/91] Train Loss 2.769 Acc 1.000\n",
      "[ 20/91] Train Loss 2.895 Acc 0.000\n",
      "[ 30/91] Train Loss 2.939 Acc 0.000\n",
      "[ 40/91] Train Loss 3.036 Acc 0.000\n",
      "[ 50/91] Train Loss 3.053 Acc 0.000\n",
      "[ 60/91] Train Loss 3.016 Acc 0.000\n",
      "[ 70/91] Train Loss 3.133 Acc 0.000\n",
      "[ 80/91] Train Loss 3.157 Acc 0.000\n",
      "[ 90/91] Train Loss 2.841 Acc 0.000\n",
      "Epoch  22/40 Train Loss 2.999 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  22/40 Test Loss 2.978 Acc 0.000\n",
      "---------------- Epoch 23 ----------------\n",
      "[  0/91] Train Loss 3.148 Acc 0.000\n",
      "[ 10/91] Train Loss 2.763 Acc 0.969\n",
      "[ 20/91] Train Loss 2.892 Acc 0.000\n",
      "[ 30/91] Train Loss 2.931 Acc 0.000\n",
      "[ 40/91] Train Loss 3.043 Acc 0.000\n",
      "[ 50/91] Train Loss 3.053 Acc 0.000\n",
      "[ 60/91] Train Loss 3.018 Acc 0.000\n",
      "[ 70/91] Train Loss 3.136 Acc 0.000\n",
      "[ 80/91] Train Loss 3.160 Acc 0.000\n",
      "[ 90/91] Train Loss 2.837 Acc 0.000\n",
      "Epoch  23/40 Train Loss 2.999 Acc 0.069\n",
      "---------------- Testing ----------------\n",
      "Epoch  23/40 Test Loss 2.977 Acc 0.000\n",
      "---------------- Epoch 24 ----------------\n",
      "[  0/91] Train Loss 3.153 Acc 0.000\n",
      "[ 10/91] Train Loss 2.757 Acc 0.969\n",
      "[ 20/91] Train Loss 2.890 Acc 0.000\n",
      "[ 30/91] Train Loss 2.928 Acc 0.000\n",
      "[ 40/91] Train Loss 3.047 Acc 0.000\n",
      "[ 50/91] Train Loss 3.054 Acc 0.000\n",
      "[ 60/91] Train Loss 3.016 Acc 0.000\n",
      "[ 70/91] Train Loss 3.139 Acc 0.000\n",
      "[ 80/91] Train Loss 3.160 Acc 0.000\n",
      "[ 90/91] Train Loss 2.833 Acc 0.000\n",
      "Epoch  24/40 Train Loss 2.998 Acc 0.067\n",
      "---------------- Testing ----------------\n",
      "Epoch  24/40 Test Loss 2.975 Acc 0.000\n",
      "---------------- Epoch 25 ----------------\n",
      "[  0/91] Train Loss 3.158 Acc 0.000\n",
      "[ 10/91] Train Loss 2.750 Acc 0.906\n",
      "[ 20/91] Train Loss 2.886 Acc 0.000\n",
      "[ 30/91] Train Loss 2.920 Acc 0.000\n",
      "[ 40/91] Train Loss 3.055 Acc 0.000\n",
      "[ 50/91] Train Loss 3.052 Acc 0.000\n",
      "[ 60/91] Train Loss 3.022 Acc 0.000\n",
      "[ 70/91] Train Loss 3.142 Acc 0.000\n",
      "[ 80/91] Train Loss 3.168 Acc 0.000\n",
      "[ 90/91] Train Loss 2.831 Acc 0.000\n",
      "Epoch  25/40 Train Loss 2.997 Acc 0.062\n",
      "---------------- Testing ----------------\n",
      "Epoch  25/40 Test Loss 2.973 Acc 0.000\n",
      "---------------- Epoch 26 ----------------\n",
      "[  0/91] Train Loss 3.160 Acc 0.000\n",
      "[ 10/91] Train Loss 2.748 Acc 0.844\n",
      "[ 20/91] Train Loss 2.891 Acc 0.000\n",
      "[ 30/91] Train Loss 2.920 Acc 0.000\n",
      "[ 40/91] Train Loss 3.050 Acc 0.000\n",
      "[ 50/91] Train Loss 3.046 Acc 0.000\n",
      "[ 60/91] Train Loss 3.025 Acc 0.000\n",
      "[ 70/91] Train Loss 3.132 Acc 0.000\n",
      "[ 80/91] Train Loss 3.171 Acc 0.000\n",
      "[ 90/91] Train Loss 2.844 Acc 0.000\n",
      "Epoch  26/40 Train Loss 2.997 Acc 0.059\n",
      "---------------- Testing ----------------\n",
      "Epoch  26/40 Test Loss 2.970 Acc 0.000\n",
      "---------------- Epoch 27 ----------------\n",
      "[  0/91] Train Loss 3.166 Acc 0.000\n",
      "[ 10/91] Train Loss 2.744 Acc 0.812\n",
      "[ 20/91] Train Loss 2.892 Acc 0.000\n",
      "[ 30/91] Train Loss 2.919 Acc 0.000\n",
      "[ 40/91] Train Loss 3.048 Acc 0.000\n",
      "[ 50/91] Train Loss 3.046 Acc 0.000\n",
      "[ 60/91] Train Loss 3.009 Acc 0.000\n",
      "[ 70/91] Train Loss 3.117 Acc 0.000\n",
      "[ 80/91] Train Loss 3.169 Acc 0.000\n",
      "[ 90/91] Train Loss 2.836 Acc 0.000\n",
      "Epoch  27/40 Train Loss 2.995 Acc 0.054\n",
      "---------------- Testing ----------------\n",
      "Epoch  27/40 Test Loss 2.964 Acc 0.000\n",
      "---------------- Epoch 28 ----------------\n",
      "[  0/91] Train Loss 3.180 Acc 0.000\n",
      "[ 10/91] Train Loss 2.722 Acc 0.812\n",
      "[ 20/91] Train Loss 2.891 Acc 0.000\n",
      "[ 30/91] Train Loss 2.918 Acc 0.000\n",
      "[ 40/91] Train Loss 3.057 Acc 0.000\n",
      "[ 50/91] Train Loss 3.054 Acc 0.000\n",
      "[ 60/91] Train Loss 3.017 Acc 0.000\n",
      "[ 70/91] Train Loss 3.110 Acc 0.000\n",
      "[ 80/91] Train Loss 3.160 Acc 0.000\n",
      "[ 90/91] Train Loss 2.830 Acc 0.000\n",
      "Epoch  28/40 Train Loss 2.993 Acc 0.059\n",
      "---------------- Testing ----------------\n",
      "Epoch  28/40 Test Loss 2.958 Acc 0.000\n",
      "---------------- Epoch 29 ----------------\n",
      "[  0/91] Train Loss 3.190 Acc 0.000\n",
      "[ 10/91] Train Loss 2.706 Acc 0.844\n",
      "[ 20/91] Train Loss 2.884 Acc 0.000\n",
      "[ 30/91] Train Loss 2.900 Acc 0.000\n",
      "[ 40/91] Train Loss 3.086 Acc 0.000\n",
      "[ 50/91] Train Loss 3.056 Acc 0.000\n",
      "[ 60/91] Train Loss 3.009 Acc 0.000\n",
      "[ 70/91] Train Loss 3.104 Acc 0.000\n",
      "[ 80/91] Train Loss 3.161 Acc 0.000\n",
      "[ 90/91] Train Loss 2.815 Acc 0.000\n",
      "Epoch  29/40 Train Loss 2.991 Acc 0.057\n",
      "---------------- Testing ----------------\n",
      "Epoch  29/40 Test Loss 2.955 Acc 0.000\n",
      "---------------- Epoch 30 ----------------\n",
      "[  0/91] Train Loss 3.189 Acc 0.000\n",
      "[ 10/91] Train Loss 2.703 Acc 0.812\n",
      "[ 20/91] Train Loss 2.873 Acc 0.000\n",
      "[ 30/91] Train Loss 2.884 Acc 0.000\n",
      "[ 40/91] Train Loss 3.084 Acc 0.000\n",
      "[ 50/91] Train Loss 3.064 Acc 0.000\n",
      "[ 60/91] Train Loss 3.009 Acc 0.000\n",
      "[ 70/91] Train Loss 3.108 Acc 0.000\n",
      "[ 80/91] Train Loss 3.138 Acc 0.000\n",
      "[ 90/91] Train Loss 2.824 Acc 0.000\n",
      "Epoch  30/40 Train Loss 2.989 Acc 0.052\n",
      "---------------- Testing ----------------\n",
      "Epoch  30/40 Test Loss 2.952 Acc 0.065\n",
      "---------------- Epoch 31 ----------------\n",
      "[  0/91] Train Loss 3.181 Acc 0.000\n",
      "[ 10/91] Train Loss 2.732 Acc 0.594\n",
      "[ 20/91] Train Loss 2.884 Acc 0.000\n",
      "[ 30/91] Train Loss 2.871 Acc 0.000\n",
      "[ 40/91] Train Loss 3.130 Acc 0.000\n",
      "[ 50/91] Train Loss 3.051 Acc 0.000\n",
      "[ 60/91] Train Loss 3.038 Acc 0.000\n",
      "[ 70/91] Train Loss 3.100 Acc 0.000\n",
      "[ 80/91] Train Loss 3.145 Acc 0.000\n",
      "[ 90/91] Train Loss 2.825 Acc 0.389\n",
      "Epoch  31/40 Train Loss 2.988 Acc 0.045\n",
      "---------------- Testing ----------------\n",
      "Epoch  31/40 Test Loss 2.957 Acc 0.677\n",
      "---------------- Epoch 32 ----------------\n",
      "[  0/91] Train Loss 3.171 Acc 0.000\n",
      "[ 10/91] Train Loss 2.763 Acc 0.188\n",
      "[ 20/91] Train Loss 2.897 Acc 0.000\n",
      "[ 30/91] Train Loss 2.922 Acc 0.000\n",
      "[ 40/91] Train Loss 3.022 Acc 0.000\n",
      "[ 50/91] Train Loss 3.012 Acc 0.000\n",
      "[ 60/91] Train Loss 3.054 Acc 0.000\n",
      "[ 70/91] Train Loss 2.985 Acc 0.000\n",
      "[ 80/91] Train Loss 3.207 Acc 0.000\n",
      "[ 90/91] Train Loss 2.820 Acc 0.389\n",
      "Epoch  32/40 Train Loss 2.987 Acc 0.027\n",
      "---------------- Testing ----------------\n",
      "Epoch  32/40 Test Loss 2.952 Acc 0.548\n",
      "---------------- Epoch 33 ----------------\n",
      "[  0/91] Train Loss 3.219 Acc 0.000\n",
      "[ 10/91] Train Loss 2.778 Acc 0.188\n",
      "[ 20/91] Train Loss 2.901 Acc 0.000\n",
      "[ 30/91] Train Loss 3.024 Acc 0.000\n",
      "[ 40/91] Train Loss 2.972 Acc 0.000\n",
      "[ 50/91] Train Loss 3.089 Acc 0.000\n",
      "[ 60/91] Train Loss 2.932 Acc 0.000\n",
      "[ 70/91] Train Loss 3.154 Acc 0.000\n",
      "[ 80/91] Train Loss 3.135 Acc 0.000\n",
      "[ 90/91] Train Loss 2.815 Acc 0.111\n",
      "Epoch  33/40 Train Loss 2.997 Acc 0.012\n",
      "---------------- Testing ----------------\n",
      "Epoch  33/40 Test Loss 2.945 Acc 0.452\n",
      "---------------- Epoch 34 ----------------\n",
      "[  0/91] Train Loss 3.218 Acc 0.000\n",
      "[ 10/91] Train Loss 2.727 Acc 0.562\n",
      "[ 20/91] Train Loss 2.921 Acc 0.000\n",
      "[ 30/91] Train Loss 2.969 Acc 0.000\n",
      "[ 40/91] Train Loss 2.984 Acc 0.000\n",
      "[ 50/91] Train Loss 3.068 Acc 0.000\n",
      "[ 60/91] Train Loss 2.939 Acc 0.000\n",
      "[ 70/91] Train Loss 3.099 Acc 0.000\n",
      "[ 80/91] Train Loss 3.155 Acc 0.000\n",
      "[ 90/91] Train Loss 2.859 Acc 0.056\n",
      "Epoch  34/40 Train Loss 2.989 Acc 0.040\n",
      "---------------- Testing ----------------\n",
      "Epoch  34/40 Test Loss 2.923 Acc 0.323\n",
      "---------------- Epoch 35 ----------------\n",
      "[  0/91] Train Loss 3.260 Acc 0.000\n",
      "[ 10/91] Train Loss 2.553 Acc 0.500\n",
      "[ 20/91] Train Loss 2.944 Acc 0.000\n",
      "[ 30/91] Train Loss 2.972 Acc 0.000\n",
      "[ 40/91] Train Loss 2.968 Acc 0.000\n",
      "[ 50/91] Train Loss 3.075 Acc 0.000\n",
      "[ 60/91] Train Loss 2.890 Acc 0.000\n",
      "[ 70/91] Train Loss 3.213 Acc 0.000\n",
      "[ 80/91] Train Loss 3.077 Acc 0.000\n",
      "[ 90/91] Train Loss 2.764 Acc 0.111\n",
      "Epoch  35/40 Train Loss 2.991 Acc 0.039\n",
      "---------------- Testing ----------------\n",
      "Epoch  35/40 Test Loss 2.952 Acc 0.097\n",
      "---------------- Epoch 36 ----------------\n",
      "[  0/91] Train Loss 3.141 Acc 0.000\n",
      "[ 10/91] Train Loss 2.491 Acc 0.875\n",
      "[ 20/91] Train Loss 2.605 Acc 0.000\n",
      "[ 30/91] Train Loss 3.009 Acc 0.000\n",
      "[ 40/91] Train Loss 2.995 Acc 0.000\n",
      "[ 50/91] Train Loss 3.075 Acc 0.000\n",
      "[ 60/91] Train Loss 2.864 Acc 0.000\n",
      "[ 70/91] Train Loss 3.215 Acc 0.000\n",
      "[ 80/91] Train Loss 3.040 Acc 0.000\n",
      "[ 90/91] Train Loss 2.760 Acc 0.056\n",
      "Epoch  36/40 Train Loss 2.973 Acc 0.057\n",
      "---------------- Testing ----------------\n",
      "Epoch  36/40 Test Loss 2.965 Acc 0.161\n",
      "---------------- Epoch 37 ----------------\n",
      "[  0/91] Train Loss 3.110 Acc 0.000\n",
      "[ 10/91] Train Loss 2.761 Acc 0.531\n",
      "[ 20/91] Train Loss 2.814 Acc 0.000\n",
      "[ 30/91] Train Loss 2.576 Acc 0.000\n",
      "[ 40/91] Train Loss 3.338 Acc 0.000\n",
      "[ 50/91] Train Loss 3.122 Acc 0.000\n",
      "[ 60/91] Train Loss 2.885 Acc 0.000\n",
      "[ 70/91] Train Loss 3.206 Acc 0.000\n",
      "[ 80/91] Train Loss 3.025 Acc 0.000\n",
      "[ 90/91] Train Loss 2.749 Acc 0.500\n",
      "Epoch  37/40 Train Loss 2.992 Acc 0.039\n",
      "---------------- Testing ----------------\n",
      "Epoch  37/40 Test Loss 2.971 Acc 0.903\n",
      "---------------- Epoch 38 ----------------\n",
      "[  0/91] Train Loss 3.095 Acc 0.000\n",
      "[ 10/91] Train Loss 2.806 Acc 0.000\n",
      "[ 20/91] Train Loss 2.905 Acc 0.000\n",
      "[ 30/91] Train Loss 2.948 Acc 0.000\n",
      "[ 40/91] Train Loss 2.963 Acc 0.000\n",
      "[ 50/91] Train Loss 3.079 Acc 0.000\n",
      "[ 60/91] Train Loss 2.905 Acc 0.000\n",
      "[ 70/91] Train Loss 3.182 Acc 0.000\n",
      "[ 80/91] Train Loss 3.024 Acc 0.000\n",
      "[ 90/91] Train Loss 2.763 Acc 0.444\n",
      "Epoch  38/40 Train Loss 2.993 Acc 0.010\n",
      "---------------- Testing ----------------\n",
      "Epoch  38/40 Test Loss 2.950 Acc 0.645\n",
      "---------------- Epoch 39 ----------------\n",
      "[  0/91] Train Loss 3.113 Acc 0.000\n",
      "[ 10/91] Train Loss 2.765 Acc 0.438\n",
      "[ 20/91] Train Loss 2.876 Acc 0.000\n",
      "[ 30/91] Train Loss 2.865 Acc 0.031\n",
      "[ 40/91] Train Loss 3.027 Acc 0.000\n",
      "[ 50/91] Train Loss 3.250 Acc 0.000\n",
      "[ 60/91] Train Loss 2.936 Acc 0.000\n",
      "[ 70/91] Train Loss 3.190 Acc 0.000\n",
      "[ 80/91] Train Loss 2.920 Acc 0.000\n",
      "[ 90/91] Train Loss 2.745 Acc 0.556\n",
      "Epoch  39/40 Train Loss 2.982 Acc 0.062\n",
      "---------------- Testing ----------------\n",
      "Epoch  39/40 Test Loss 2.943 Acc 0.645\n",
      "---------------- Epoch 40 ----------------\n",
      "[  0/91] Train Loss 3.045 Acc 0.000\n",
      "[ 10/91] Train Loss 2.787 Acc 0.000\n",
      "[ 20/91] Train Loss 2.918 Acc 0.000\n",
      "[ 30/91] Train Loss 2.948 Acc 0.000\n",
      "[ 40/91] Train Loss 2.942 Acc 0.000\n",
      "[ 50/91] Train Loss 3.011 Acc 0.000\n",
      "[ 60/91] Train Loss 3.007 Acc 0.000\n",
      "[ 70/91] Train Loss 3.198 Acc 0.000\n",
      "[ 80/91] Train Loss 2.900 Acc 0.000\n",
      "[ 90/91] Train Loss 2.755 Acc 0.389\n",
      "Epoch  40/40 Train Loss 2.987 Acc 0.029\n",
      "---------------- Testing ----------------\n",
      "Epoch  40/40 Test Loss 2.928 Acc 0.516\n",
      "--------------------\n",
      "The Best accuracy is 0.903 at epoch 37\n"
     ]
    }
   ],
   "source": [
    "# move model to GPU if available\n",
    "\n",
    "if device == 'cuda':\n",
    "    mymodel.cuda()\n",
    "\n",
    "model = model.to(device)   \n",
    "    \n",
    "# for recording\n",
    "train_loss, test_loss = [], []\n",
    "train_acc, test_acc = [], []\n",
    "best_acc = (0, 0.0) # (epoch, acc)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"---------------- Epoch {} ----------------\".format(epoch+1))\n",
    "    \n",
    "    # training\n",
    "    loss, acc = train(1, model, train_loader, criterion,optimizer)\n",
    "    # saving epoch loss and acc for plotting\n",
    "    train_loss.append(loss)\n",
    "    train_acc.append(acc)\n",
    "    # logging\n",
    "    print('Epoch {:3d}/{} Train Loss {:.3f} Acc {:.3f}'.format(epoch+1, EPOCHS, loss, acc))\n",
    "    \n",
    "    # testing\n",
    "    print(\"---------------- Testing ----------------\")\n",
    "    loss, acc = test(model,test_loader,criterion)\n",
    "    test_loss.append(loss)\n",
    "    test_acc.append(acc)        \n",
    "    # logging\n",
    "    print('Epoch {:3d}/{} Test Loss {:.3f} Acc {:.3f}'.format(epoch+1, EPOCHS, loss, acc))\n",
    "    \n",
    "    if acc > best_acc[1]:\n",
    "        best_acc = (epoch+1, acc)\n",
    "\n",
    "print('--' * 10)\n",
    "print('The Best accuracy is {:.3f} at epoch {}'.format(best_acc[1], best_acc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492892fb",
   "metadata": {},
   "source": [
    "### 3.3 儲存模型\n",
    "PyTorch 提供 ```torch.save()``` API 可以儲存模型。\n",
    "\n",
    "PyTorch 建議使用 ```state_dict``` 來儲存模型(要存整個模型也可以)，```state_dict``` 包含模型的可學習參數(如 conv layers 的 weight 和 bias) 以及 registered buffer (如 batchnorm running mean) 。 由於 ```state_dict``` 屬於 python dictionaries ，所以有很大的使用彈性。\n",
    "\n",
    "這裡我們只儲存最後的模型狀態，你也可以在每一個 epoch 後儲存一個節點或儲存擁有最佳表現的模型。常用的附檔名為 ```.pt``` 或 ```.pth```。\n",
    "\n",
    "請完成以下 ? 處。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34aaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'mymodel.pth'\n",
    "torch.save(?, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8d5c6",
   "metadata": {},
   "source": [
    "### 3.4 繪製訓練過程的 loss 與 accuracy 變化\n",
    "在訓練過程中，我們透過 ```list``` 儲存每個 epoch 的 loss 和 accuracy，現在透過 ```matplotlib.pyplot``` 將這些數值畫成圖表，可以幫助我們分析訓練過程的變化。\n",
    "\n",
    "請完成以下 ? 處"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting loss curves\n",
    "x = list(range(EPOCHS))\n",
    "plt.plot(x, ?, x, ?)\n",
    "plt.title('Training & Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Testing'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f465ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting acc curves\n",
    "x = list(range(EPOCHS))\n",
    "plt.plot(x, ?, x, ?)\n",
    "plt.title('Training & Testing Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Testing'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2336d",
   "metadata": {},
   "source": [
    "## 參考資料 & 教學\n",
    "\n",
    "### Transformations\n",
    "+ https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n",
    "+ https://pytorch.org/vision/stable/transforms.html 可以知道每種方法產生的效果\n",
    "+ https://chih-sheng-huang821.medium.com/03-pytorch-dataaug-a712a7a7f55e\n",
    "\n",
    "### Dataset\n",
    "+ https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
    "+ https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "\n",
    "### Dataloader\n",
    "+ https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders\n",
    "\n",
    "### Model\n",
    "#### Module\n",
    "+ https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "+ https://pytorch.org/docs/stable/nn.html (conv, batchnorm, pooling layer 的詳細用法可以在這裡找到)\n",
    "\n",
    "#### Custom Model\n",
    "+ https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html\n",
    "\n",
    "#### nn.Sequential\n",
    "+ https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
    "\n",
    "### Training\n",
    "#### Optimizer\n",
    "+ https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "#### Loss function\n",
    "+ https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "\n",
    "#### Saving model\n",
    "+ https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
